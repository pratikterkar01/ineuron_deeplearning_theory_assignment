1. Describe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?
Ans=the artificial neuron network is based on the function of the biological neural network .
In the biological neural network all the inputs are taken by receptors and processed to give the output passing through various process like that the artificial neural networks work. The main components of the neural network is  neuron also called perceptron ,hidden layers and finally output layers.to join the percptron we use weights and for processing bais is used 

2. What are the different types of activation functions popularly used? Explain each of them.
Ans=The activation used in the dl is differentiated as linear and non-linear dataset.
1.linear activation function
a)binary  step activation function :- it gives two out put either 0 (for x<0 )or 1(for x >0) . This function is also known as haveside step function 
2.Non-linear function
a)sigmoid function or logistic activation function :-The graph of this function is in the shape                                                                                                                             of s curve.
It is used because it legives the output as 0 or 1 so this function is used for where we need to predict the  probability.
-this function is differentiable so we can find the slop at any point
-the drawbacks of this function is it stuck at training time,Non-zero centre ,vanishing gradient , computing expensive
-eq.=1/1+e-1
b) tanh activation function:-  this activation is betterment  of sigmoid function. This function range  
from (-1,1) .
--the advantages is maping the negative inputs strongly.
--generally used for classification for two class. Both function is used for feed forward network
--satureted function , not using in  last output layer
c) Relu  function :-relu is half rectified function 0( when z<0) and infinity (when z>0)
--its advantage is converging will be fast 
--one drawback is all negative value become zero immediately which decreases the ability of the 
--dying the neuron
d) Leaky Relu:-i
e)Parameter Relu (prelu):-
f)Exponential Relu ( Erelu):-
g)Scaled Exponential (SELU):-

3.Explain, in details, Rosenblatt's perceptron model. How can a set of data be classified using a simple perceptron?
Ans=

4.Use a simple perceptron with weights w0, w1, and w2 as -1, 2, and 1, respectively, to classify data points (3, 4); (5, 2); (1, -3); (-8-, -3); (-3, 0).
Ans=1st  output =(2*3+4*1)-1=9
         2nd output=(5*2+2*2)-1=11
      3rd output = (1*2-3*1)-1=-2
4th output=(-8*2-3*1)-1=-20
5th output=(-3*2+0*1)-1=-7
3. Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR problem.
Ans= XOR or Exclusive OR gives boolen type of output if inputs of perceptron are different then it     give output as true otherwise False
A	B	Output
0	0	0
0	1	1
1	0	1
1	1	1

4. What is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for classification ANN.
Ans= An Artificial Neural Network (ANN) is an information processing paradigm that is inspired by the brain. ANNs, like people, learn by examples. An ANN is configured for a specific application, such as pattern recognition or data, through a learning process.

Explain the learning process of an ANN. Explain, with example, the challenge in assigning synaptic weights for the interconnection between neurons? How can this challenge be addressed?
Ans= So, we can summarize the learning process in ANN as the combination of - deciding the number of hidden layers, the number of nodes in each of the hidden layers, the direction of signal flow, deciding the connection weight.
In neuroscience and computer science, synaptic weight refers to the strength or amplitude of a connection between two nodes, corresponding in biology to the amount of influence the firing of one neuron has on another. The term is typically used in artificial and biological neural network research.



5. Explain, in details, the backpropagation algorithm. What are the limitations of this algorithm?
Ans = Backpropagation is used to train the neural network of the chain rule method. In simple terms, after each feed-forward passes through a network, this algorithm does the backward pass to adjust the model's parameters based on weights and biases.
The biggest disadvantages of backpropagation are: Backpropagation could be rather sensitive to noisy data and irregularity. The performance of backpropagation relies very heavily on the training data. Backpropagation needs a very large amount of time for training.
.


6.  Describe in details, the process of adjusting the interconnection weights in a multi-layer neural network.
Ans = The backpropagation algorithm is applicable for multi-layer feed-forward network. It is a supervised learning algorithm which continues adjusting the weights of the connected neurons with an objective to reduce the deviation of the output signal from the target output.

7. What are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?
Ans = Step 1: Inputs X, arrive through the preconnected path.
          Step 2: The input is modeled using true weights W. Weights are usually chosen randomly.
          Step 3: Calculate the output of each neuron from the input layer to the hidden layer to the    output layer.
The model with more number of neurons per layer and more number of layer has higher representational capacity, in turn, is capable to map any complicated function OR Model is capable to extract any level complex features from out input datasets.


8. Write short notes on:
1. Artificial neuron
2. Multi-layer perceptron
3. Deep learning
4. rate Learning
1) The artificial neuron receives one or more inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or activation, representing a neuron's action potential which is transmitted along its axon). An artificial neural network consists of simulated neurons. Each neuron is connected to other nodes via links like a biological axon-synapse-dendrite connection. All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data.

A multilayer perceptron (MLP) is a fully connected class of feedforward artificial neural network (ANN). The term MLP is used ambiguously, sometimes loosely to mean any feedforward ANN, sometimes strictly to refer to networks composed of multiple layers of perceptrons (with threshold activation) An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a chain rule[2] based supervised learning technique called backpropagation or reverse mode of automatic differentiation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable. 

3) Deep learning is a method in artificial intelligence (AI) that teaches computers to process data in a way that is inspired by the human brain. Deep learning models can recognize complex patterns in pictures, text, sounds, and other data to produce accurate insights and predictions.
Deep Learning involves taking large volumes of structured or unstructured data and using complex algorithms to train neural networks. It performs complex operations to extract hidden patterns and features

4) A learning rate schedule changes the learning rate during learning and is most often changed between epochs/iterations. This is mainly done with two parameters: decay and momentum. There are many different learning rate schedules but the most common are time-based, step-based and exponential.

9. Write the difference between:-
1. Activation function vs threshold function
2. Step function vs sigmoid function.
3. Single layer vs multi-layer perceptron

